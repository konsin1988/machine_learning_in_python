{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1377847e-e10f-4a77-8d24-77babae7951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3c733f-def8-48b9-a6a1-c3e8411332a3",
   "metadata": {},
   "source": [
    "# decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21b5ce-9738-4d54-9f61-edd49f690dd3",
   "metadata": {},
   "source": [
    "### Преимущества и недостатки деревьев решений\n",
    "##### Преимущества:\n",
    "\n",
    "-    **Интерпретируемость**: Одним из главных преимуществ деревьев решений является их легкость в интерпретации. Конечные пользователи могут легко понять, какие признаки были важны для предсказания.\n",
    "\n",
    "-    **Гибкость**: Деревья решений могут использоваться как для классификации, так и для регрессии. Их можно адаптировать к различным типам задач.\n",
    "\n",
    "-    **Отсутствие необходимости нормализации данных**: Деревья решений не требуют нормализации признаков, так как они работают только с разделениями данных.\n",
    "\n",
    "-    **Устойчивость к выбросам**: Деревья решений менее чувствительны к выбросам, поскольку они концентрируются на разделениях, основанных на выборках, а не на отдельных значениях.\n",
    "\n",
    "##### Недостатки:\n",
    "\n",
    "-    **Переобучение**: Без применения ограничений (например, максимальной глубины) деревья могут сильно переобучаться, особенно на малых выборках.\n",
    "\n",
    "-    **Нестабильность**: Небольшие изменения в данных могут привести к значительным изменениям структуры дерева, что делает модель менее устойчивой.\n",
    "\n",
    "-    **Меньшая точность по сравнению с ансамблями**: Деревья решений по своей природе менее точны, чем более сложные методы, такие как случайные леса (Random Forests) или градиентный бустинг (Gradient Boosting).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb03cdc-63cb-44be-9ba8-3109f160562c",
   "metadata": {},
   "source": [
    "### Переобучение в деревьях решений.\n",
    "В чем оно проявляется?\n",
    "\n",
    "-    Глубокие деревья: Дерево может создавать множество уровней, чтобы разделить каждую точку данных, даже если это вызвано шумом или случайными выбросами.\n",
    "  \n",
    "-    Чрезмерно детализированные разделения: Дерево может разделять данные до тех пор, пока не достигнет уровня, где каждая конечная группа (лист) будет содержать одно или несколько наблюдений. Это приводит к тому, что дерево подстраивается под мелкие особенности данных.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44243662-2a47-4a26-a1ca-59aede656415",
   "metadata": {},
   "source": [
    "### 1. Ограничение глубины дерева\n",
    "<div class='alert alert-box alert-success'>\n",
    "\n",
    "```Ограничение глубины контролирует, насколько детализированным будет дерево. Меньшая глубина заставляет дерево принимать обобщённые решения и уменьшает вероятность переобучения.```\n",
    "</div>\n",
    "\n",
    "```from sklearn.tree import DecisionTreeClassifier```\n",
    "\n",
    "##### Ограничиваем глубину дерева до 5 уровней\n",
    "```tree = DecisionTreeClassifier(max_depth=5, random_state=42)```<br>\n",
    "```tree.fit(X_train, y_train)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd7159e-3f5c-4377-8fc7-79c30b770c6f",
   "metadata": {},
   "source": [
    "### 2. Минимальное количество объектов в листе (min_samples_leaf)\n",
    "<div class='alert alert-box alert-success'>\n",
    "\n",
    "```Если конечный лист содержит слишком мало объектов, это может говорить о чрезмерной подстройке дерева под конкретные объекты. Увеличивая значение min_samples_leaf, мы требуем, чтобы дерево обрабатывало только более значимые группы объектов.```\n",
    "</div>\n",
    "\n",
    "```from sklearn.tree import DecisionTreeClassifier```\n",
    "\n",
    "##### Минимум 10 объектов в каждом листе\n",
    "```tree = DecisionTreeClassifier(min_samples_leaf=10, random_state=42)```<br>\n",
    "```tree.fit(X_train, y_train)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8131348-d052-4e1b-b46b-b41e3b107dec",
   "metadata": {},
   "source": [
    "### 3. Минимальное количество объектов для разбиения (min_samples_split)\n",
    "<div class='alert alert-box alert-success'>\n",
    "\n",
    "```Когда количество объектов в узле становится слишком малым, дальнейшее разбиение может не принести пользы, а лишь усложнит модель. Ограничение минимального числа объектов для разбиения заставляет дерево принимать более обобщённые решения.```\n",
    "</div>\n",
    "\n",
    "```from sklearn.tree import DecisionTreeClassifier```\n",
    "\n",
    "##### Минимум 20 объектов для разбиения узла\n",
    "```tree = DecisionTreeClassifier(min_samples_split=20, random_state=42)```<br>\n",
    "```tree.fit(X_train, y_train)```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea97638-941d-456a-8091-a71438c6b4de",
   "metadata": {},
   "source": [
    "### 4. Обрезка дерева (pruning)\n",
    "<div class='alert alert-box alert-success'>\n",
    "\n",
    "```Обрезка (pruning) — это процесс удаления узлов дерева, которые не дают значимого улучшения на новых данных. Этот метод применяется после построения дерева, чтобы удалить ненужные ветви, которые могут быть результатом подгонки под обучающую выборку.```\n",
    "</div>\n",
    "Существует два вида обрезки:\n",
    "\n",
    "-    **Предварительная обрезка (Pre-pruning)**: Разбиения ограничиваются до того, как дерево будет построено полностью (задаётся через параметры max_depth, min_samples_leaf и т.д.).\n",
    "-    **Пост-обрезка (Post-pruning)**: Обрезка выполняется после построения дерева. В sklearn это реализовано через параметр ccp_alpha, который задаёт величину регуляризации. Узлы, которые дают минимальное улучшение, удаляются, упрощая модель. Этот параметр задаёт силу регуляризации — чем выше значение, тем больше узлов будет обрезано.\n",
    "\n",
    "\n",
    "```from sklearn.tree import DecisionTreeClassifier```<br>\n",
    "```from sklearn.model_selection import GridSearchCV```\n",
    "\n",
    "##### Настраиваем параметр ccp_alpha для пост-обрезки\n",
    "```param_grid = {'ccp_alpha': [0.001, 0.01, 0.1, 0.5]}```<br>\n",
    "```tree = DecisionTreeClassifier(min_samples_split=20, random_state=42)```<br>\n",
    "```tree.fit(X_train, y_train)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9b655-3241-4004-81a8-9d395dafaf23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

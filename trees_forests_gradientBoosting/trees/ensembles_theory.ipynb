{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5165fd63-2564-4302-a810-bd5d07b64b73",
   "metadata": {},
   "source": [
    "# Бутстрап и его применение в машинном обучении"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9931fa4-3cf6-4fb0-94d4-b08fa004cf22",
   "metadata": {},
   "source": [
    ">Бутстрап (bootstrap) — это статистический метод, широко используемый для оценки распределений статистик путём многократного повторного выборочного извлечения из исходных данных с возвратом. Иными словами, бутстрап создаёт множество подвыборок из исходных данных, каждая из которых используется для анализа, что помогает улучшить точность предсказаний и снизить влияние выбросов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977e4dd-0d64-4c4b-b0b8-544565527301",
   "metadata": {},
   "source": [
    "<div class = 'alert alert-box alert-success'>\n",
    "    \n",
    "```Бутстрап основан на идее выборки с возвратом (resampling with replacement). Это значит, что для каждой подвыборки мы выбираем случайные объекты из исходного набора данных, и выбранный объект может повторяться в одной подвыборке несколько раз. Поскольку выборка производится с возвратом, некоторые объекты исходной выборки могут не попасть в бутстрап-подвыборку.```\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186ffef-d6ba-4b98-b3c7-5c63a08183d2",
   "metadata": {},
   "source": [
    "#### Применение бутстрапа в машинном обучении\n",
    "\n",
    "-    Мы создаём несколько бутстрап-подвыборок из исходного набора данных.\n",
    "-    Для каждой подвыборки строится отдельная модель.\n",
    "-    Все модели обучаются независимо друг от друга на своих подвыборках, что делает модели разнообразными.\n",
    "-    Итоговое предсказание получается путём голосования или усреднения предсказаний всех моделей, построенных на бутстрап-подвыборках\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec67ac6-652c-45b7-b5a1-26195d7013d8",
   "metadata": {},
   "source": [
    "# Ансамблевое обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77756d5-4ee1-4ea8-814b-38c6611db693",
   "metadata": {},
   "source": [
    "**Bagging** и **Boosting** - известные методы ансамблевого обучения, широко используемые для улучшения прогнозов моделей. \n",
    "Баггинг (или бэггинг) предполагает построение нескольких моделей с использованием подмножества исходного набора данных, а затем агрегирование их индивидуальных прогнозов для получения окончательного прогноза. Эти методы, как и деревья решений, предполагают введение рандомизации при построении модели, чтобы уменьшить дисперсию модели (overfitting). Методы суммирования хорошо работают со сложными моделями, такими как деревья решений, которые имеют большую глубину. Методы группировки различаются по способу получения подмножеств из исходного набора данных и имеют следующие названия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fac7c9-9e6f-4806-829b-f29b2ffed6c9",
   "metadata": {},
   "source": [
    "### Методы группировки:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e926a5cd-99c8-4bec-8d2a-55c61cfb5240",
   "metadata": {},
   "source": [
    "### 1. Pasting (создание подвыборок без замены)\n",
    "\n",
    ">Когда мы берем случайное подмножество объектов из исходного набора данных, без возврата, эта техника называется Pasting. Это означает, что один и тот же объект не может быть включён в подвыборку более одного раза. Образцы берутся случайным образом, но, как только они были взяты, они больше не возвращаются в набор данных для повторного выбора. Pasting полезен, когда мы хотим создать разные подвыборки из данных и избежать дублирования объектов. Эта техника позволяет создать разнообразные подвыборки, не полагаясь на повторяющиеся данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da069b8-56fd-4fdf-99ba-e083605dcc6b",
   "metadata": {},
   "source": [
    "### 2. Bootstrapping (создание подвыборок с заменой)\n",
    "\n",
    ">Когда мы выбираем случайные подвыборки данных с заменой, эта техника называется **Bootstrapping**. Это означает, что после того, как объект был выбран, он снова возвращается в набор данных и может быть выбран повторно. Таким образом, одно и то же наблюдение может появиться в подвыборке несколько раз, а некоторые объекты из исходного набора данных могут не попасть в подвыборку вообще. Если у вас есть набор данных из 100 объектов, вы можете создать бутстрап-подвыборку из 100 объектов, при этом некоторые из них будут дублироваться, а другие могут быть не включены. Bootstrapping помогает снизить влияние выбросов и шума в данных, так как случайные подвыборки часто не будут включать выбросы. Этот метод используется, например, в методе Bagging, который помогает улучшить обобщающую способность модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe31040-ee3d-40bd-b00f-833c2cd54c91",
   "metadata": {},
   "source": [
    "### 3. Random Subspaces (случайные подпространства)\n",
    "\n",
    ">Когда мы выбираем случайные подмножества признаков для построения моделей, эта техника называется Random Subspaces. В отличие от предыдущих техник, где выбирались объекты, здесь выбираются случайные подмножества признаков (или переменных), которые используются для построения моделей. Это позволяет снизить влияние отдельных признаков и улучшить обобщающую способность модели. Если у вас есть 10 признаков (например, возраст, вес, рост и т.д.), случайные подпространства могут выбрать 5 признаков для создания подмножества, которое будет использоваться для обучения модели. Random Subspaces часто применяются в задачах, где много признаков, и некоторые из них могут быть неинформативными или коррелированными. Эта техника используется в таких алгоритмах, как Random Forest, где случайное подмножество признаков выбирается для каждого разбиения в деревьях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bafc75-c360-4fbe-8b69-a317f816c888",
   "metadata": {},
   "source": [
    "### 4. Random Patches (случайные подмножества как объектов, так и признаков)\n",
    "\n",
    ">Когда мы создаём модели, используя случайные подмножества как объектов, так и признаков, эта техника называется Random Patches. Этот метод комбинирует принципы Pasting и Random Subspaces, создавая подмножества данных по двум осям: объекты и признаки. Это позволяет ещё сильнее разнообразить подвыборки, что снижает риск переобучения и делает модели более устойчивыми. Из набора данных с 1000 объектов и 20 признаков, метод Random Patches может выбрать 500 случайных объектов и 10 случайных признаков для построения каждой модели. Random Patches полезен для построения устойчивых моделей, которые не зависят от конкретных объектов или признаков. Он используется в задачах, где нужно работать с большими наборами данных и множеством признаков, что делает этот метод идеальным для применения в ансамблевых моделях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9cc3a2-81de-420d-a83f-24ff5a7c3999",
   "metadata": {},
   "source": [
    "<center><img height=\"84\" name=\"image.png\" src=\"https://ucarecdn.com/36d9eb81-261e-497a-a4ea-452c4fb6fbc3/\" width=\"452\"></center>\n",
    "<center><img height=\"242\" name=\"image.png\" src=\"https://ucarecdn.com/9d7db180-8e2b-4032-b4f0-64c8aef84abb/\" width=\"403\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64f0955-cf23-4761-b642-b22538124224",
   "metadata": {},
   "source": [
    "# Случайные леса\n",
    "В Random forests мы берем несколько деревьев решений и строим модели на основе набора данных. Берется несколько выборок из набора данных с заменой (**бутстраппинг**) и на их основе строится модель дерева решений. Деревья решений склонны к переобучению при большой глубине. Случайные леса борются с избыточным соответствием обучающему набору, тщательно выбирая количество признаков, которые выбираются для каждого отдельного дерева решений. Также случайный лес борется с влиянием выбросов благодаря бутстрапу, тк бутстрап позволяет минимизировать влияние выбросов, на которых переобучается обычное дерево. Таким образом, случайные леса демонстрируют хорошие прогностические характеристики. Scikit Learn предоставляет реализацию алгоритмов случайных лесов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb3fee3-0cf3-40c1-8efe-7413069d873a",
   "metadata": {},
   "source": [
    "<center><img alt=\"\" height=\"230\" name=\"image.png\" src=\"https://ucarecdn.com/a5592657-2dac-482d-9b25-73c99913bc58/\" width=\"409\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23f48b6-0488-4921-ab27-4e323ed6ee13",
   "metadata": {},
   "source": [
    "## Бустинг\n",
    "**Бустинг** - одна из самых распространенных техник ансамблевых моделей. Это последовательный процесс, в котором каждая следующая модель пытается исправить предсказания предыдущих моделей. Модели бустинга строят несколько слабых моделей, а затем на их основе строят сильную модель. Одна слабая модель может хорошо работать на подмножестве набора данных. Их объединение повышает общую производительность. Градиентный бустинг: Это особый случай бустинга, в котором ошибки минимизируются с помощью алгоритмов оптимизации, таких как градиентный спуск.\n",
    "\n",
    "Известные алгоритмы бустинга\n",
    "Это алгоритмы, работа которых основана на семействе ансамблевых моделей Boosting.\n",
    "\n",
    "    AdaBoost\n",
    "    Gradient Tree Boosting или Gradient Boosted Decision Trees или Gradient Boosting Machines (GBDT или GBM)\n",
    "    Градиентный бустинг на основе гистограмм\n",
    "    XGBoost (Extreme Gradient Boosting)\n",
    "    LightGBM\n",
    "    CatBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94cdbf0-e7a6-41eb-808b-0ca98b5fd126",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

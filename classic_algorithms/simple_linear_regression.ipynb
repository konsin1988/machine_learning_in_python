{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5957dce-5c67-4f33-90e1-c0a06b2f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b60621-b19e-46d3-bb7e-6aef770af1da",
   "metadata": {},
   "source": [
    ">Линейная регрессия — это одна из простейших моделей машинного обучения, используемая для предсказания значения целевой переменной на основе одной или нескольких независимых переменных (признаков). В данной модели зависимость между целевой переменной y и признаками X предполагается линейной, что означает, что каждое изменение признаков приводит к пропорциональному изменению целевой переменной."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73594ef8-ed82-408b-a434-b6011b2fdef5",
   "metadata": {},
   "source": [
    "$$ y_{prediction} = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + ... + \\beta_nx_x$$\n",
    "\n",
    ">$y$ — целевая переменная, которую мы пытаемся предсказать, \\\n",
    "$x_1$,…,$x_n$ — независимые переменные (или признаки), \\\n",
    "$β_0$ — свободный член (интерсепт), который представляет собой значение целевой переменной при нулевых значениях всех признаков,\\\n",
    "$β_1,…,β_n$ — коэффициенты регрессии, показывающие влияние каждого признака на целевую переменную"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcecf146-f8a2-4d59-9065-bd6e2035e0d9",
   "metadata": {},
   "source": [
    "$$цена\\ дома=A∗площадь+B∗количество\\ комнат+...+Y∗удаленность\\ от\\ метро+Z...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bafbeb-ef0a-40c5-a5e2-d679009a5765",
   "metadata": {},
   "source": [
    ">Задача **минимизации функции** потерь может быть сформулирована как задача нахождения таких параметров модели θθ , при которых значение функции потерь L(θ)L(θ)  достигает своего минимума. Это может быть записано как:\n",
    "\n",
    "$$ min_\\theta L(\\theta)$$\n",
    "\n",
    ">где θ — это вектор параметров модели, а L(θ) — это функция потерь, зависящая от этих параметров. Вектор параметров может содержать коэффициенты регрессии, веса нейронной сети или другие переменные, которые определяют поведение модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b304eb0-ea8c-4cd2-8053-e93c8451f38a",
   "metadata": {},
   "source": [
    "## Градиент как направление наибольшего изменения\n",
    ">Одним из наиболее эффективных и популярных методов численной оптимизации в машинном обучении (поиска локального минимума функции потерь, то есть тех весов модели, которые приводят к наименьшей ошибке) является градиентный спуск. Этот метод основан на вычислении градиента функции потерь. Градиент — это вектор, который указывает направление наибольшего роста функции. В случае минимизации, мы движемся в направлении, противоположном градиенту, чтобы уменьшить значение функции потерь.\n",
    "\n",
    "<center><img alt=\"\" height=\"284\" name=\"image.png\" src=\"https://ucarecdn.com/672288ab-0182-4d3d-aa54-2ce63a305c61/\" width=\"431\"></center>\n",
    "\n",
    "Параметры модели обновляются по следующему правилу:\n",
    "\n",
    "$$ \\theta := \\theta - \\alpha \\cdot \\nabla L(\\theta )$$\n",
    "\n",
    "α — это скорость обучения (learning rate), которая определяет, насколько большие шаги делаются при каждом обновлении параметров,\n",
    "∇L(θ) — это градиент функции потерь по параметрам θ, показывающий направление наибольшего увеличения значения функции потерь. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ec6a0b-ed5f-4843-b5af-e415163f52d2",
   "metadata": {},
   "source": [
    "## Процесс градиентного спуска\n",
    "\n",
    "-    Инициализация параметров: Начинаем с какого-то начального набора параметров θθ, которые могут быть заданы случайно или на основе априорных знаний.\n",
    "\n",
    "-    Вычисление градиента: На каждом шаге вычисляется градиент функции потерь по каждому параметру модели. Градиент показывает, насколько сильно изменение каждого параметра повлияет на изменение значения функции потерь.\n",
    "\n",
    "-    Обновление параметров: Параметры корректируются в направлении, противоположном градиенту, чтобы уменьшить значение функции потерь.\n",
    "\n",
    "-    Повторение итераций: Этот процесс повторяется до тех пор, пока не будет достигнут минимум функции потерь или до тех пор, пока изменения в параметрах становятся незначительными.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a6167d-64e1-4889-aec6-2880326d47e0",
   "metadata": {},
   "source": [
    "### Скорость обучения и её влияние\n",
    "\n",
    "> Одним из ключевых параметров градиентного спуска является скорость обучения (α). Скорость обучения определяет, насколько большими будут шаги обновления параметров на каждом этапе. Если скорость обучения слишком мала, процесс минимизации будет очень медленным. Если же скорость обучения слишком велика, модель может перепрыгнуть через минимум функции потерь и не достичь оптимальных значений параметров.\n",
    "\n",
    "> Выбор правильного значения скорости обучения — это важная часть настройки градиентного спуска. В некоторых случаях применяются методы адаптивной регулировки скорости обучения, которые уменьшают её значение по мере приближения к минимуму.\n",
    "\n",
    "<center><img alt=\"\" height=\"238\" name=\"image.png\" src=\"https://ucarecdn.com/6e616d5b-3411-4fb8-9757-03865391a730/\" width=\"426\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0066c-7c1b-4b79-869c-53b7f1f91a37",
   "metadata": {},
   "source": [
    "### Проблемы и улучшения градиентного спуска\n",
    "\n",
    ">Хотя градиентный спуск — это мощный и эффективный метод оптимизации, у него есть свои ограничения. Например, при наличии нескольких локальных минимумов функция потерь может \"застрять\" в одном из них и не достичь глобального минимума. Для преодоления этой проблемы были разработаны различные модификации градиентного спуска, такие как стохастический градиентный спуск (SGD), который работает с случайными подвыборками данных, или методы с импульсом (momentum), которые учитывают предыдущие направления изменения параметров, что помогает избежать локальных минимумов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae1cc5a-bf7e-4b3c-bffb-0628a88fc830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
